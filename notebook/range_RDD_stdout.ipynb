{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "range-RDD-stdout.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNJV156bBgqm"
      },
      "source": [
        "# Setup\n",
        "# 1. JDK\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# 2. Spark\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "\n",
        "# 3. Envs\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "\n",
        "# 4. PySpark\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAxdY9oaAzOT",
        "outputId": "0ec26c3b-7383-4398-912a-b721f3b35257"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "\n",
        "# Local SparkContext using N threads (N = number of logical processors)\n",
        "sc = SparkContext(master=\"local[*]\", appName=\"range-RDD-stdout\")\n",
        "\n",
        "# 1. Input data: list of integers (unstructured batch)\n",
        "data = range(1, 10001)\n",
        "print(f\"Input data: {len(data)} integers from {data[0]} to {data[9999]}\")\n",
        "\n",
        "# 2. Data processing\n",
        "# Parallelize input data into a RDD (lazy evaluation) using * partitions\n",
        "rangeRDD = sc.parallelize(data)\n",
        "print(f\"RDD has been created using {rangeRDD.getNumPartitions()} partitions\")\n",
        "\n",
        "# Process data using lambda functions and collect results:\n",
        "# 1) substract 1 to all elements. 2) select those lower than 10.\n",
        "out = (rangeRDD\n",
        "       .map(lambda y: y - 1)\n",
        "       .filter(lambda x: x < 10)\n",
        "       .collect())\n",
        "\n",
        "# 3. Output data: show result in the standard output (console)\n",
        "print(f\"The output is {out}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data: 10000 integers from 1 to 10000\n",
            "RDD has been created using 2 partitions\n",
            "The output is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}